{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação com KNN e SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que os dados já foram processados, a segunda parte do projeto consiste em usar modelos de aprendizado de máquina para ver se conseguimos encontrar algum atributo (tecidos) que permitam uma classificação com boa acurácia.\n",
    "\n",
    "Mesmo que o resultado obtido seja bom ou ruim, temos que lembrar que os dados vieram de uma população diversificada em relação à idade e ao grau de esquizofrenia, assim como o tempo de acompanhamento de cada indivíduo (mais informações podem ser encontradas no link: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3358772/).\n",
    "\n",
    "A base é dividida em treino e teste, e a partição de teste não é utilizada para treinar, de forma a evitar que o classificador seja enviesado.\n",
    "\n",
    "Serão definidas algumas funções auxiliares para essa parte.\n",
    "\n",
    "| Função | Descrição |\n",
    "|---|---|\n",
    "|<pre>prepare_dataset(conditions_to_drop, features_to_use)</pre> | Essa função recebe uma lista com as condições (classes) para remover, quando deseja-se descartar informações dos irmãos dos pacientes esquizofrênicos ou dos controles. Isso pode ser de interesse pois aumenta o número de classes para classificar, sendo que os irmãos de esquizofrênicos não necessariamente tem o mesmo transtorno, e eles possuem uma maior disposição à desenvolver o transtorno bipolar, podendo confundir o classificador. Além disso, há uma outra lista que contém os atributos para usar, quando se deseja usar mais de um ou quando queremos variar o que está sendo usado para ver como afeta a classificação |\n",
    "|<pre>knn(X_train, X_test, y_train, y_test)</pre> | Recebe as partições de treino e teste e realiza o treino de um classificador KNN com número de vizinhos igual a 3, e então calcula a acurácia utilizando a partição de testes |\n",
    "|<pre>svm(X_train, X_test, y_train, y_test)</pre> | Recebe as partições de treino e teste e realiza o treino de um classificador SVM com kernel linear, e então calcula a acurácia utilizando a partição de testes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Função para criar o dataset\n",
    "def prepare_dataset(conditions_to_drop, features_to_use):\n",
    "    \n",
    "    dataset = pd.read_csv('../data/processed.csv', header=0, sep=',')\n",
    "\n",
    "    for c in conditions_to_drop:\n",
    "        dataset = dataset.drop(dataset[dataset['condition'] == c].index)\n",
    "    \n",
    "    X = dataset[features_to_use].values\n",
    "    y = dataset['condition'].tolist()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.20, stratify=y, shuffle=True)\n",
    "\n",
    "    print(f'\\tForam separados {len(X_train)} dados para treino, e {len(X_test)} dados para teste')\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def knn(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    print('\\tAcurácia KNN:', accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "def svm(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = SVC(gamma='auto', shrinking=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print('\\tAcurácia SVM:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificando utilizando white-gray-relation\n",
      "Considerando os irmãos:\n",
      "\tForam separados 72 dados para treino, e 19 dados para teste\n",
      "\tAcurácia KNN: 0.21052631578947367\n",
      "\tAcurácia SVM: 0.3684210526315789\n",
      "Desconsiderando os irmãos\n",
      "\tForam separados 30 dados para treino, e 8 dados para teste\n",
      "\tAcurácia KNN: 0.875\n",
      "\tAcurácia SVM: 0.75\n",
      "------------------------------------------------\n",
      "Classificando utilizando white-matter\n",
      "Considerando os irmãos:\n",
      "\tForam separados 72 dados para treino, e 19 dados para teste\n",
      "\tAcurácia KNN: 0.10526315789473684\n",
      "\tAcurácia SVM: 0.3684210526315789\n",
      "Desconsiderando os irmãos\n",
      "\tForam separados 30 dados para treino, e 8 dados para teste\n",
      "\tAcurácia KNN: 0.625\n",
      "\tAcurácia SVM: 0.5\n",
      "------------------------------------------------\n",
      "Classificando utilizando gray-matter\n",
      "Considerando os irmãos:\n",
      "\tForam separados 72 dados para treino, e 19 dados para teste\n",
      "\tAcurácia KNN: 0.3684210526315789\n",
      "\tAcurácia SVM: 0.3684210526315789\n",
      "Desconsiderando os irmãos\n",
      "\tForam separados 30 dados para treino, e 8 dados para teste\n",
      "\tAcurácia KNN: 0.5\n",
      "\tAcurácia SVM: 0.5\n",
      "------------------------------------------------\n",
      "Classificando utilizando csf-matter\n",
      "Considerando os irmãos:\n",
      "\tForam separados 72 dados para treino, e 19 dados para teste\n",
      "\tAcurácia KNN: 0.15789473684210525\n",
      "\tAcurácia SVM: 0.3684210526315789\n",
      "Desconsiderando os irmãos\n",
      "\tForam separados 30 dados para treino, e 8 dados para teste\n",
      "\tAcurácia KNN: 0.625\n",
      "\tAcurácia SVM: 0.5\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "feature = ['white-gray-relation', 'white-matter', 'gray-matter', 'csf-matter']\n",
    "\n",
    "for f in feature:\n",
    "    print(f'Classificando utilizando {f}')\n",
    "    \n",
    "    print('Considerando os irmãos:')\n",
    "    # Considerando os irmãos\n",
    "    X_train, X_test, y_train, y_test = prepare_dataset([], [f])\n",
    "    knn(X_train, X_test, y_train, y_test)\n",
    "    svm(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    print('Desconsiderando os irmãos')\n",
    "    # Desconsiderando os irmãos\n",
    "    X_train, X_test, y_train, y_test = prepare_dataset(['SCZ-SIB', 'CON-SIB'], [f])\n",
    "    knn(X_train, X_test, y_train, y_test)\n",
    "    svm(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    print('------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussão dos resultados\n",
    "\n",
    "Pelas acuárias, podemos ver que sempre que os irmãos dos esquizofrênicos e do controle são utilizados, os dois classificadores não conseguem atingir uma acurácia maior que 0.3. Esse número pode ser baixo, mas é necessário um estudo mais aprofundado para decidir se é um bom resultado ou não (uma acurácia baixa que supera a acuária de alguns médicos já é suficiente para dizer que o modelo tem um bom desempenho, mas é preciso avaliar se esse resultado ocorreu ao acaso (utilizando um teste estatístico de p-valor)).\n",
    "\n",
    "Quando são utilizados apenas pacientes esquizofrênicos e controle, a acuária é sempre maior ou igual que 0.5 para qualquer tecido que seja utilizado como atributo. O que apresenta maior acurácia é quando utilizamos a relação entre massa branca/massa cinzenta como atributo, obtendo uma acurácia de 0.875. Outro cuidado que temos que tomar aqui é que tanto a partição de treino quanto a de teste não são absurdamente grandes. Alguns modelos requerem uma quantidade muito grande de dados para proporcionar uma boa tarefa de predição, então apesar do alto valor, um estudo mais detalhado faz-se necessário para afirmar que os modelos realmente apresentaram um desempenho bom).\n",
    "\n",
    "De forma geral, os modelos apresentam dados interessantes mas devemos tomar cuidado ao interpretar os dados ou tirar conclusões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
